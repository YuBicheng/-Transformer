{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4164167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695e018",
   "metadata": {},
   "source": [
    "将文本中的标点去掉，并且去除多余字符\\\n",
    "源文件：Hi.\t嗨。\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #891077 (Martha)\\\n",
    "清洗后的：Hi\t嗨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9daab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23635\n",
      "['你', '好']\n",
      "英文最长词数： 32 中文最长词数 43\n"
     ]
    }
   ],
   "source": [
    "#训练集的比例\n",
    "train_proportion = 0.8\n",
    "with open(\"./cmn.txt\",'r',encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "trainset_len = int(len(lines)*train_proportion)\n",
    "print(trainset_len)\n",
    "en_maxwords = 0\n",
    "ch_maxwords = 0\n",
    "with open(\"./train.txt\",'w',encoding='utf8') as f1:\n",
    "    with open('./test.txt','w',encoding='utf8') as f2:\n",
    "        for i in range(len(lines)):\n",
    "            #将一行按制表符分割\n",
    "            line = lines[i].split('\\t')\n",
    "            #去标点\n",
    "            cleaned_en = re.sub(\"[,|.|!|?]\",'',line[0])\n",
    "            cleaned_ch = re.sub(\"[,|,|.|。|?|？|！|!]\", '', line[1])\n",
    "            len_en = len(cleaned_en.split(' '))\n",
    "            if len_en>en_maxwords:\n",
    "                en_maxwords = len_en\n",
    "            cuted_ch = list(cleaned_ch)\n",
    "            if i ==1:\n",
    "                print(cuted_ch)\n",
    "            len_ch = len(cuted_ch)\n",
    "            if len_ch>ch_maxwords:\n",
    "                ch_maxwords = len_ch\n",
    "            final_ch = ' '.join(cuted_ch)\n",
    "            cleaned_line = cleaned_en + '\\t' + final_ch + '\\n'\n",
    "            if i<trainset_len:\n",
    "                f1.write(cleaned_line)\n",
    "            else:\n",
    "                f2.write(cleaned_line)\n",
    "    \n",
    "        #英文最长词数： 32 中文最长词数 29\n",
    "print(\"英文最长词数：\",en_maxwords,\"中文最长词数\",ch_maxwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8b3b6",
   "metadata": {},
   "source": [
    "通过清洗后的数据分别训练中文和英文的Word2Vector词嵌入模型，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a57c75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文此表大小 74\n",
      "中文此表大小 3641\n"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "with open('./cleaned_cmn.txt','r',encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "en_sentences = []\n",
    "ch_sentences = []\n",
    "for line in lines:\n",
    "    en_sentences.append(line.split('\\t')[0])\n",
    "    ch_sentences.append(line.split('\\t')[1])\n",
    "en_model = Word2Vec(en_sentences,vector_size=d_model,min_count=1,workers=3)\n",
    "#英文此表大小 74\n",
    "print('英文词表大小',len(en_model.wv.index_to_key))\n",
    "en_model.save('enw2v.model')\n",
    "ch_model = Word2Vec(ch_sentences,vector_size=d_model,min_count=1,workers=3)\n",
    "#中文此表大小 3641\n",
    "print('中文词表大小',len(ch_model.wv.index_to_key))\n",
    "ch_model.save('chw2v.model')"
   ]
  },
  
}
